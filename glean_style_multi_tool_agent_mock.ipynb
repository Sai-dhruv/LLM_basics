{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bced2c59",
   "metadata": {},
   "source": [
    "# Gleanâ€‘Style Multiâ€‘Tool Agent with LangChain + LangGraph (Mock Demo)\n",
    "\n",
    "This notebook shows how to build a **Gleanâ€‘style enterprise assistant** using:\n",
    "\n",
    "- **LangChain** for LLMs and prompts  \n",
    "- **LangGraph** for multiâ€‘step / multiâ€‘agent orchestration  \n",
    "- **Mock tools** that simulate:\n",
    "  - Google Docs\n",
    "  - Gmail\n",
    "  - Slack\n",
    "  - Jira\n",
    "  - Local knowledge base\n",
    "\n",
    "No real APIs are called â€“ everything is **inâ€‘memory mock data**, so you can run this safely without credentials.\n",
    "\n",
    "---\n",
    "\n",
    "## Highâ€‘Level Architecture\n",
    "\n",
    "Weâ€™ll build a simple agent workflow:\n",
    "\n",
    "1. **Router Agent (LLM)**  \n",
    "   - Looks at the user question  \n",
    "   - Decides which â€œtoolâ€ is most relevant (google_docs / gmail / slack / jira / local_kb)  \n",
    "   - Outputs a small JSON with `tool` and `tool_query`\n",
    "\n",
    "2. **Tool Executor Node (Python)**  \n",
    "   - Calls the selected tool function on our mock data  \n",
    "   - Returns a `tool_result` string\n",
    "\n",
    "3. **Answer Agent (LLM)**  \n",
    "   - Takes `question + tool_result`  \n",
    "   - Generates a nice, userâ€‘friendly answer\n",
    "\n",
    "All of this is wired together with **LangGraph**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ad0af7",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies (if needed)\n",
    "\n",
    "Run this cell once to install the necessary libraries.\n",
    "\n",
    "> ðŸ’¡ If you already installed these in your environment, you can skip this or ignore any \"already satisfied\" messages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f92e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install core libs for this notebook.\n",
    "# You can comment this out if everything is already installed.\n",
    "\n",
    "#%pip install -q langchain langchain-core langchain-community langchain-openai langgraph langchain-text-splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4cd571",
   "metadata": {},
   "source": [
    "## 2. Imports & LLM Setup\n",
    "\n",
    "We will use **OpenAI** via `langchain-openai`.  \n",
    "You need an OpenAI API key (`OPENAI_API_KEY`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0586e141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM ready.\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Any, List, Dict\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# ðŸ‘‰ Put your OpenAI API key here (or use environment variable if you prefer)\n",
    "OPENAI_API_KEY = \"sk-REPLACE_ME\"\n",
    "\n",
    "# Create a small, cheap LLM for routing and answering.\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "print(\"LLM ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cb34e4",
   "metadata": {},
   "source": [
    "## 3. Mock Data Sources (Fake Gleanâ€‘Style Backends)\n",
    "\n",
    "Instead of calling real Slack / Jira / Gmail / Google Docs APIs,  \n",
    "weâ€™ll create **inâ€‘memory dictionaries and lists** that simulate each system.\n",
    "\n",
    "This keeps the notebook fully selfâ€‘contained and safe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f618b50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mock data sources initialized.\n"
     ]
    }
   ],
   "source": [
    "# --- Mock Google Docs ---\n",
    "MOCK_GOOGLE_DOCS: Dict[str, str] = {\n",
    "    \"doc_resume\": \"\"\"\n",
    "Saikrishna Vinjamuri is a Senior Data Engineer and GenAI developer.\n",
    "Tech stack: Python, Java, AWS, Glue, Lambda, RDS, DynamoDB, Kafka, Spark,\n",
    "LangChain, LangGraph, OpenAI, Cohere, Pinecone, Snowflake, dbt, Airflow.\n",
    "\"\"\",\n",
    "\n",
    "    \"doc_policy\": \"\"\"\n",
    "Remote Work Policy:\n",
    "Employees may work remotely up to 3 days per week.\n",
    "All remote work must comply with data security and VPN usage standards.\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "# --- Mock Gmail inbox ---\n",
    "MOCK_GMAIL: List[Dict[str, str]] = [\n",
    "    {\n",
    "        \"from\": \"manager@example.com\",\n",
    "        \"subject\": \"Deployment delayed\",\n",
    "        \"body\": \"The production deployment is delayed due to failing integration tests.\"\n",
    "    },\n",
    "    {\n",
    "        \"from\": \"recruiter@example.com\",\n",
    "        \"subject\": \"Interview schedule\",\n",
    "        \"body\": \"We would like to schedule a technical interview next Tuesday.\"\n",
    "    },\n",
    "]\n",
    "\n",
    "# --- Mock Slack messages ---\n",
    "MOCK_SLACK_CHANNELS: Dict[str, List[str]] = {\n",
    "    \"#eng-team\": [\n",
    "        \"We need to add monitoring for the new feature store pipeline.\",\n",
    "        \"Reminder: standup is at 10 AM CST.\",\n",
    "    ],\n",
    "    \"#genai-poc\": [\n",
    "        \"The LangGraph-based Glean-style agent is almost ready.\",\n",
    "        \"Need to add Jira integration and Gmail summarization.\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# --- Mock Jira issues ---\n",
    "MOCK_JIRA_ISSUES: List[Dict[str, str]] = [\n",
    "    {\n",
    "        \"key\": \"ENG-101\",\n",
    "        \"summary\": \"Create RAG pipeline for internal docs\",\n",
    "        \"status\": \"In Progress\"\n",
    "    },\n",
    "    {\n",
    "        \"key\": \"ENG-102\",\n",
    "        \"summary\": \"Fix Glue job for feature store exports\",\n",
    "        \"status\": \"To Do\"\n",
    "    },\n",
    "]\n",
    "\n",
    "# --- Mock Local Knowledge Base ---\n",
    "MOCK_LOCAL_DOCS: List[str] = [\n",
    "    \"Feature store SDK enables ML engineers to register and query features.\",\n",
    "    \"LangGraph is used to orchestrate agents and tools in GenAI systems.\",\n",
    "    \"Snowflake, Kafka, and dbt are core components of the data platform.\",\n",
    "]\n",
    "\n",
    "print(\"Mock data sources initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abeb71d",
   "metadata": {},
   "source": [
    "## 4. Define Tool Functions (Pure Python)\n",
    "\n",
    "Each tool is a **normal Python function** that knows how to query one data source.\n",
    "\n",
    "The LLM will not call them directly using the builtâ€‘in OpenAI tools mechanism â€“  \n",
    "instead, we will:\n",
    "\n",
    "1. Ask an LLM **which tool to use** (router step)  \n",
    "2. Call the selected tool from Python (LangGraph node)  \n",
    "3. Then pass the tool result back into another LLM to generate the final answer  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7abe7f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools registered: ['google_docs', 'gmail', 'slack', 'jira', 'local_kb']\n"
     ]
    }
   ],
   "source": [
    "def search_google_docs(query: str) -> str:\n",
    "    \"\"\"Simulate semantic search over mock Google Docs (very simple contains filter).\"\"\"\n",
    "    query_lower = query.lower()\n",
    "    hits = []\n",
    "    for doc_id, content in MOCK_GOOGLE_DOCS.items():\n",
    "        if query_lower in content.lower():\n",
    "            hits.append(f\"[DOC: {doc_id}]\\n{content.strip()}\")\n",
    "    if not hits:\n",
    "        return \"No matching content found in Google Docs.\"\n",
    "    return \"\\n\\n---\\n\\n\".join(hits)\n",
    "\n",
    "\n",
    "def search_gmail(query: str) -> str:\n",
    "    \"\"\"Simulate search over mock Gmail messages.\"\"\"\n",
    "    query_lower = query.lower()\n",
    "    hits = []\n",
    "    for msg in MOCK_GMAIL:\n",
    "        blob = f\"From: {msg['from']}\\nSubject: {msg['subject']}\\nBody: {msg['body']}\"\n",
    "        if query_lower in blob.lower():\n",
    "            hits.append(blob)\n",
    "    if not hits:\n",
    "        return \"No matching emails found in Gmail.\"\n",
    "    return \"\\n\\n---\\n\\n\".join(hits)\n",
    "\n",
    "\n",
    "def search_slack(query: str) -> str:\n",
    "    \"\"\"Simulate search over mock Slack channels.\"\"\"\n",
    "    query_lower = query.lower()\n",
    "    hits = []\n",
    "    for channel, messages in MOCK_SLACK_CHANNELS.items():\n",
    "        for m in messages:\n",
    "            if query_lower in m.lower():\n",
    "                hits.append(f\"[Channel {channel}] {m}\")\n",
    "    if not hits:\n",
    "        return \"No matching Slack messages found.\"\n",
    "    return \"\\n\".join(hits)\n",
    "\n",
    "\n",
    "def search_jira(query: str) -> str:\n",
    "    \"\"\"Simulate search over mock Jira issues by summary / key.\"\"\"\n",
    "    query_lower = query.lower()\n",
    "    hits = []\n",
    "    for issue in MOCK_JIRA_ISSUES:\n",
    "        blob = f\"{issue['key']}: {issue['summary']} (Status: {issue['status']})\"\n",
    "        if query_lower in blob.lower():\n",
    "            hits.append(blob)\n",
    "    if not hits:\n",
    "        return \"No matching Jira issues found.\"\n",
    "    return \"\\n\".join(hits)\n",
    "\n",
    "\n",
    "def search_local_kb(query: str) -> str:\n",
    "    \"\"\"Simulate search over a small local knowledge base list.\"\"\"\n",
    "    query_lower = query.lower()\n",
    "    hits = []\n",
    "    for doc in MOCK_LOCAL_DOCS:\n",
    "        if query_lower in doc.lower():\n",
    "            hits.append(doc)\n",
    "    if not hits:\n",
    "        return \"No relevant local knowledge found.\"\n",
    "    return \"\\n\".join(hits)\n",
    "\n",
    "\n",
    "# A registry so we can map tool names (strings) to functions\n",
    "TOOL_REGISTRY = {\n",
    "    \"google_docs\": search_google_docs,\n",
    "    \"gmail\": search_gmail,\n",
    "    \"slack\": search_slack,\n",
    "    \"jira\": search_jira,\n",
    "    \"local_kb\": search_local_kb,\n",
    "}\n",
    "\n",
    "print(\"Tools registered:\", list(TOOL_REGISTRY.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e39ecd",
   "metadata": {},
   "source": [
    "## 5. Router Agent (LLM)\n",
    "\n",
    "The **Router Agent** decides which tool to use based on the user question.\n",
    "\n",
    "Weâ€™ll prompt the LLM to output a **small JSON** with two fields:\n",
    "\n",
    "- `tool` â†’ one of: `google_docs`, `gmail`, `slack`, `jira`, `local_kb`  \n",
    "- `tool_query` â†’ what we should search for inside that tool\n",
    "\n",
    "Example output:\n",
    "\n",
    "```json\n",
    "{\"tool\": \"gmail\", \"tool_query\": \"deployment\"}\n",
    "```\n",
    "\n",
    "Weâ€™ll parse this JSON in Python and pass it into the Tool Executor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "068e7545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tool': 'google_docs', 'tool_query': 'resume tech stack'}\n",
      "{'tool': 'jira', 'tool_query': 'feature store'}\n",
      "{'tool': 'gmail', 'tool_query': 'deployment'}\n"
     ]
    }
   ],
   "source": [
    "ROUTER_SYSTEM_PROMPT = \"\"\"\n",
    "You are a routing assistant for an enterprise knowledge agent.\n",
    "\n",
    "Your job:\n",
    "- Look at the user's question\n",
    "- Decide which ONE data source is best to answer it:\n",
    "    - `google_docs`  -> if question is about resumes, policies, docs content\n",
    "    - `gmail`        -> if question is about emails\n",
    "    - `slack`        -> if question is about team chats or channels\n",
    "    - `jira`         -> if question is about tasks, tickets, issues, work items\n",
    "    - `local_kb`     -> if question is about internal platform / architecture notes\n",
    "\n",
    "Respond ONLY with a valid JSON object with keys:\n",
    "- \"tool\": one of [\"google_docs\", \"gmail\", \"slack\", \"jira\", \"local_kb\"]\n",
    "- \"tool_query\": a short text query to search for in that tool\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def router_agent(question: str) -> Dict[str, str]:\n",
    "    \"\"\"Call LLM to decide which tool to use and what query to run.\"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=ROUTER_SYSTEM_PROMPT),\n",
    "        HumanMessage(content=question),\n",
    "    ]\n",
    "    resp = llm.invoke(messages)\n",
    "    raw = resp.content.strip()\n",
    "    # Try to parse JSON; if it fails, fall back to a default\n",
    "    try:\n",
    "        parsed = json.loads(raw)\n",
    "        tool = parsed.get(\"tool\", \"local_kb\")\n",
    "        tool_query = parsed.get(\"tool_query\", question)\n",
    "    except Exception:\n",
    "        tool, tool_query = \"local_kb\", question\n",
    "\n",
    "    return {\"tool\": tool, \"tool_query\": tool_query}\n",
    "\n",
    "\n",
    "# Quick smoke test of router:\n",
    "print(router_agent(\"Summarize my resume tech stack from Google Docs.\"))\n",
    "print(router_agent(\"Any Jira tickets about feature store?\"))\n",
    "print(router_agent(\"What emails mention deployment?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21ca7fc",
   "metadata": {},
   "source": [
    "## 6. Define LangGraph State and Nodes\n",
    "\n",
    "Weâ€™ll use a small state dictionary passed between nodes:\n",
    "\n",
    "```python\n",
    "class AgentState(TypedDict):\n",
    "    question: str\n",
    "    tool: str\n",
    "    tool_query: str\n",
    "    tool_result: str\n",
    "    answer: str\n",
    "```\n",
    "\n",
    "### Nodes\n",
    "\n",
    "1. `route_node`  \n",
    "   - Uses `router_agent` to set `tool` + `tool_query`\n",
    "\n",
    "2. `tool_node`  \n",
    "   - Looks up the Python function for `tool`  \n",
    "   - Calls it with `tool_query`  \n",
    "   - Stores the result in `tool_result`\n",
    "\n",
    "3. `answer_node`  \n",
    "   - Calls LLM with `question` + `tool_result`  \n",
    "   - Produces final `answer`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "580902a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict, total=False):\n",
    "    question: str\n",
    "    tool: str\n",
    "    tool_query: str\n",
    "    tool_result: str\n",
    "    answer: str\n",
    "\n",
    "\n",
    "def route_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"LangGraph node: decide which tool to call.\"\"\"\n",
    "    question = state[\"question\"]\n",
    "    routing = router_agent(question)\n",
    "    return {\n",
    "        \"tool\": routing[\"tool\"],\n",
    "        \"tool_query\": routing[\"tool_query\"],\n",
    "    }\n",
    "\n",
    "\n",
    "def tool_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"LangGraph node: execute the selected tool on the tool_query.\"\"\"\n",
    "    tool_name = state.get(\"tool\", \"local_kb\")\n",
    "    tool_query = state.get(\"tool_query\", state[\"question\"])\n",
    "    tool_fn = TOOL_REGISTRY.get(tool_name)\n",
    "\n",
    "    if tool_fn is None:\n",
    "        result = f\"Unknown tool '{tool_name}'. No result.\"\n",
    "    else:\n",
    "        result = tool_fn(tool_query)\n",
    "\n",
    "    return {\"tool_result\": result}\n",
    "\n",
    "\n",
    "ANSWER_SYSTEM_PROMPT = \"\"\"\n",
    "You are an enterprise assistant (Glean-style).\n",
    "\n",
    "You receive:\n",
    "- The user's original question\n",
    "- Results from one backend tool (Google Docs / Gmail / Slack / Jira / local KB)\n",
    "\n",
    "Your job:\n",
    "- Use the tool results to answer clearly and concisely.\n",
    "- If the tool result says there were no matches, say that honestly.\n",
    "- If relevant, mention which source you used (Docs, Gmail, Slack, Jira, Local KB).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def answer_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"LangGraph node: generate final answer using question + tool_result.\"\"\"\n",
    "    question = state[\"question\"]\n",
    "    tool_name = state.get(\"tool\", \"local_kb\")\n",
    "    tool_result = state.get(\"tool_result\", \"\")\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=ANSWER_SYSTEM_PROMPT),\n",
    "        HumanMessage(\n",
    "            content=(\n",
    "                f\"User question: {question}\\n\\n\"\n",
    "                f\"Tool used: {tool_name}\\n\\n\"\n",
    "                f\"Tool result:\\n{tool_result}\"\n",
    "            )\n",
    "        ),\n",
    "    ]\n",
    "    resp = llm.invoke(messages)\n",
    "    return {\"answer\": resp.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7271105a",
   "metadata": {},
   "source": [
    "## 7. Build and Compile the LangGraph\n",
    "\n",
    "Now we wire the nodes together into a simple linear graph:\n",
    "\n",
    "```text\n",
    "route_node â†’ tool_node â†’ answer_node â†’ END\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93c3ecd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph compiled.\n"
     ]
    }
   ],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"route\", route_node)\n",
    "graph.add_node(\"tool\", tool_node)\n",
    "graph.add_node(\"answer\", answer_node)\n",
    "\n",
    "graph.set_entry_point(\"route\")\n",
    "graph.add_edge(\"route\", \"tool\")\n",
    "graph.add_edge(\"tool\", \"answer\")\n",
    "graph.add_edge(\"answer\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "print(\"Graph compiled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144cd66b",
   "metadata": {},
   "source": [
    "## 8. Try Some Example Queries\n",
    "\n",
    "Now we can send questions into the compiled graph with `app.invoke(...)`.\n",
    "\n",
    "The state we pass in only needs the `question` â€“  \n",
    "the rest will be filled stepâ€‘byâ€‘step by our nodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4da9a175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "QUESTION:\n",
      "==============================\n",
      "List the main technologies in my resume from Google Docs.\n",
      "\n",
      "Running agent...\n",
      "\n",
      "\n",
      "==============================\n",
      "FINAL ANSWER:\n",
      "==============================\n",
      "It appears that there are no matching technologies listed in your resume from Google Docs.\n",
      "\n",
      "==============================\n",
      "QUESTION:\n",
      "==============================\n",
      "Any Jira tickets that talk about feature store or Glue?\n",
      "\n",
      "Running agent...\n",
      "\n",
      "\n",
      "==============================\n",
      "FINAL ANSWER:\n",
      "==============================\n",
      "There are no matching Jira tickets that discuss feature store or Glue.\n",
      "\n",
      "==============================\n",
      "QUESTION:\n",
      "==============================\n",
      "What Slack messages mention LangGraph?\n",
      "\n",
      "Running agent...\n",
      "\n",
      "\n",
      "==============================\n",
      "FINAL ANSWER:\n",
      "==============================\n",
      "I found a Slack message that mentions LangGraph in the channel #genai-poc: \"The LangGraph-based Glean-style agent is almost ready.\"\n",
      "\n",
      "==============================\n",
      "QUESTION:\n",
      "==============================\n",
      "Do we have any emails about deployment delays?\n",
      "\n",
      "Running agent...\n",
      "\n",
      "\n",
      "==============================\n",
      "FINAL ANSWER:\n",
      "==============================\n",
      "There are no emails found regarding deployment delays in Gmail.\n",
      "\n",
      "==============================\n",
      "QUESTION:\n",
      "==============================\n",
      "What internal notes discuss the data platform components?\n",
      "\n",
      "Running agent...\n",
      "\n",
      "\n",
      "==============================\n",
      "FINAL ANSWER:\n",
      "==============================\n",
      "I couldn't find any internal notes discussing the data platform components in the local knowledge base.\n"
     ]
    }
   ],
   "source": [
    "def run_query(question: str):\n",
    "    print(\"\"\"\n",
    "==============================\n",
    "QUESTION:\n",
    "==============================\"\"\")\n",
    "    print(question)\n",
    "    print(\"\\nRunning agent...\\n\")\n",
    "\n",
    "    result_state = app.invoke({\"question\": question})\n",
    "    print(\"\"\"\n",
    "==============================\n",
    "FINAL ANSWER:\n",
    "==============================\"\"\")\n",
    "    print(result_state[\"answer\"])\n",
    "\n",
    "\n",
    "# --- Examples ---\n",
    "run_query(\"List the main technologies in my resume from Google Docs.\")\n",
    "run_query(\"Any Jira tickets that talk about feature store or Glue?\")\n",
    "run_query(\"What Slack messages mention LangGraph?\")\n",
    "run_query(\"Do we have any emails about deployment delays?\")\n",
    "run_query(\"What internal notes discuss the data platform components?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b67faec",
   "metadata": {},
   "source": [
    "## 9. Next Steps / How to Extend This\n",
    "\n",
    "You now have a **Gleanâ€‘style multiâ€‘tool agent** with:\n",
    "\n",
    "- LangChain LLM calls\n",
    "- LangGraph orchestration\n",
    "- Router â†’ Tool â†’ Answer pattern\n",
    "- Mock tools for:\n",
    "  - Google Docs\n",
    "  - Gmail\n",
    "  - Slack\n",
    "  - Jira\n",
    "  - Local knowledge base\n",
    "\n",
    "### Ideas to extend:\n",
    "- Replace mock tools with REAL APIs:\n",
    "  - Google Docs API\n",
    "  - Gmail API\n",
    "  - Slack Web API\n",
    "  - Jira Cloud REST API\n",
    "- Add **RAG** using vector stores (FAISS, Chroma) instead of simple `in` matching\n",
    "- Add more tools (Confluence, GitHub, Notion, etc.)\n",
    "- Add a memory node to keep conversation history\n",
    "- Add a UI (Streamlit / React) that sends questions to this agent\n",
    "\n",
    "You can use this notebook as an **interview demo** or a starting point for a real internal Gleanâ€‘like assistant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb55bfe-8457-489a-b957-a25dde5d9465",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
