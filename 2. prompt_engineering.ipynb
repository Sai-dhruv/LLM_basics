{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58461253-a727-4963-8a5f-f9abf2bd62fc",
   "metadata": {},
   "source": [
    "#### 2. Prompt engineering\n",
    "    a. PromptTemplates\n",
    "    b. ChatPromptTemplate\n",
    "    c. Prompt variables\n",
    "    d. Multi-turn prompts\n",
    "    e. Output Parsers\n",
    "        StrOutputParser\n",
    "        JsonOutputParser\n",
    "        PydanticOutputParser\n",
    "        Tools to enforce structured output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dee8e6f-6544-4bd1-a18d-af00c0775a30",
   "metadata": {},
   "source": [
    "These are reusable templates where you define placeholders for dynamic values. They help structure and standardize prompts so you donâ€™t manually rewrite them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fadfd44-27e6-4aa2-8969-18fa851a9a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model = \"gpt-4o-mini\",\n",
    "                 api_key = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d3fade-9b4e-45ad-8ad9-b2c710d805c1",
   "metadata": {},
   "source": [
    "### âœ… PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ae9b5a1-ad6a-41ea-8e21-18539e1ac633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain the importance of feature engineering in simple words.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Explain the importance of {topic} in simple words.\"\n",
    ")\n",
    "\n",
    "prompt = template.format(topic=\"feature engineering\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fc3a97-cac1-4cbb-9fab-d1e3fe788431",
   "metadata": {},
   "source": [
    "### âœ… ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d7c4275-93d4-4ee1-9da6-0ff50a9c3be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are an expert software engineer.\n",
      "Human: Explain retrieval augmented generation with an example.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert software engineer.\"),\n",
    "    (\"user\", \"Explain {concept} with an example.\")\n",
    "])\n",
    "\n",
    "final_prompt = prompt.format(concept=\"retrieval augmented generation\")\n",
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cca770c-e067-4d2e-87a6-feba79914d8e",
   "metadata": {},
   "source": [
    "### âœ… Using Prompt Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2008a50-11e4-4edf-8e93-34c81810d7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me a short story about a robot.\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"Tell me a {length} story about {character}.\",\n",
    "    input_variables=[\"length\", \"character\"]\n",
    ")\n",
    "\n",
    "print(prompt.format(length=\"short\", character=\"a robot\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82723ec-aea3-49cb-be8b-1feaf76fdbdd",
   "metadata": {},
   "source": [
    "### âœ… Multi-turn Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62497c61-bda4-49ea-8286-dd3e0923acbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is useful for several reasons, particularly in the context of working with language models and building applications that leverage their capabilities. Here are some key benefits:\n",
      "\n",
      "1. **Modular Components**: LangChain provides modular components that can be easily integrated to build complex applications. This includes tools for prompt management, memory handling, and chaining multiple language model calls.\n",
      "\n",
      "2. **Prompt Engineering**: It offers utilities for effective prompt design, helping users create and manage prompts that yield better responses from language models.\n",
      "\n",
      "3. **Memory Management**: LangChain supports memory features, allowing applications to maintain context over multiple interactions, which is essential for building conversational agents and other interactive applications.\n",
      "\n",
      "4. **Integration with External Data**: It allows integration with various data sources, such as APIs, databases, and document stores, enabling language models to access real-time data or specific knowledge bases.\n",
      "\n",
      "5. **Chaining Functionality**: LangChain enables users to chain together different operations, such as querying a database and then processing the results with a language model, creating sophisticated workflows.\n",
      "\n",
      "6. **Ease of Use**: It simplifies the process of building and deploying applications that utilize large language models, making it accessible for developers without deep expertise in AI.\n",
      "\n",
      "7. **Community and Ecosystem**: Being an open-source framework, LangChain has a growing community and ecosystem, providing resources, tutorials, and support for developers.\n",
      "\n",
      "Overall, LangChain streamlines the development process for applications that require natural language understanding and generation, making it a valuable tool for developers in the AI space.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"user\", \"What is LangChain?\"),\n",
    "    (\"assistant\", \"LangChain is an LLM framework.\"),\n",
    "    (\"user\", \"Why is it useful?\")\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf3375c-10be-4cac-ad84-a682436157bd",
   "metadata": {},
   "source": [
    "### ðŸ”¥  Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cee083-8de2-415a-9886-ac5ec07b8c20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
